# === ðŸ”§ BASIS-MODULE (Standardbibliothek & Basisdatenverarbeitung) ===
import json            # Verarbeitung von JSON-Dateien (z.â€¯B. Laden von Konfigurationsdaten oder Schiffseinstellungen)
import os              # Datei- und Verzeichnisoperationen (z.â€¯B. PfadprÃ¼fungen, Dateiexistenz etc.)
import pandas as pd    # Tabellenverarbeitung und Datenanalyse (z.â€¯B. Filtern, Gruppieren, Zeitreihen)
import numpy as np     # Mathematische Funktionen (z.â€¯B. Mittelwerte, NaN-Erkennung, Array-Operationen)
import pytz            # Zeitzonen-Verarbeitung und Konvertierung von Timestamps
import traceback       # Lesbare Fehler-Stacks fÃ¼r Debugging und Fehleranalyse
import io              # Pufferobjekte und Dateioperationen im Speicher
from datetime import datetime, timedelta  # Verarbeitung und Formatierung von Zeitstempeln

# === ðŸ“Š UI & VISUALISIERUNG ===
import plotly.graph_objects as go    # Interaktive Diagramme (z.â€¯B. fÃ¼r ZeitverlÃ¤ufe, Tiefenprofile)
import streamlit as st               # Haupt-Framework zur Erstellung der interaktiven Web-OberflÃ¤che

# === ðŸŒ GEODATEN & GEOMETRIE ===
from shapely.geometry import Point   # Geometrische Punkt-Objekte fÃ¼r Koordinatenberechnungen (z.â€¯B. Punkt-in-Polygon)

# === ðŸ§© EIGENE MODULE (Modularisierte Funktionsbausteine fÃ¼r einzelne Analyseschritte) ===

# ðŸŸ¡ Import- & TDS-Berechnung (Rohdaten â†’ Volumen, Masse, Konzentration)
from modul_tshd_hpa_import import konvertiere_hpa_ascii
@st.cache_data
def konvertiere_hpa_ascii_cached(files): return konvertiere_hpa_ascii(files)

from modul_tshd_mona_import import parse_mona, berechne_tds_parameter
@st.cache_data
def parse_mona_cached(files): return parse_mona(files)

# ðŸŸ¦ Statusbasierte Umlauf-Logik (Leerfahrt, Baggern, etc.)
from modul_umlaeufe import nummeriere_umlaeufe, berechne_status_neu, mappe_umlaufnummer
@st.cache_data
def extrahiere_umlauf_startzeiten_cached(*args, **kwargs):
    from modul_umlaeufe import extrahiere_umlauf_startzeiten
    return extrahiere_umlauf_startzeiten(*args, **kwargs)

@st.cache_data
def berechne_status_neu_cached(df, umlauf_info_df):
    from modul_umlaeufe import berechne_status_neu
    return berechne_status_neu(df, umlauf_info_df)

# âš“ Baggerseite automatisch erkennen (BB / SB)
from modul_baggerseite import erkenne_baggerseite

# ðŸŒ EPSG-Code automatisch ermitteln (fÃ¼r Georeferenzierung)
from modul_koordinatenerkennung import erkenne_koordinatensystem

# ðŸ“¥ XML-Import von Baggerfeldgrenzen
from modul_baggerfelder_xml_import import parse_baggerfelder
@st.cache_data
def parse_baggerfelder_cached(xml_file, epsg_code):
    from modul_baggerfelder_xml_import import parse_baggerfelder
    return parse_baggerfelder(xml_file, epsg_code)

# ðŸ“ Berechnung der Solltiefe entlang der Fahrtspur
from modul_solltiefe_tshd import berechne_solltiefe_fuer_df

# ðŸš¢ Streckenanalyse je Betriebsstatus (Leerfahrt, Baggern, Verklappen ...)
from modul_strecken import berechne_strecken

# ðŸ“Š Umlaufkennzahlen berechnen (z.â€¯B. Menge, Masse, Dichte, Dauer)
from modul_umlauf_kennzahl import berechne_umlauf_kennzahlen

# ðŸŽ¯ Start-/Endwertstrategie (z.â€¯B. aus Volumen oder VerdrÃ¤ngung)
from modul_startend_strategie import berechne_start_endwerte, STRATEGIE_REGISTRY

# ðŸ§° Hilfsfunktionen fÃ¼r Formatierung, Konvertierung, PrÃ¼fung
from modul_hilfsfunktionen import (
    convert_timestamp,                # Timestamps konvertieren inkl. Zeitzone
    erkenne_datenformat,              # Datenformat automatisch erkennen (MoNa, HPA)
    erkenne_schiff_aus_dateiname,     # Schiffsname aus Dateinamen extrahieren
    format_dauer, sichere_dauer, sichere_zeit,  # Zeitformate sicher darstellen
    format_de, format_time,           # Formatierung von Zahlen und Zeitwerten
    get_spaltenname,                  # Zugriff auf BB/SB-Spaltennamen
    lade_schiffsparameter,            # Schiffsparameter aus JSON laden
    plot_x,                           # Zeitachse fÃ¼r Plotly generieren
    pruefe_werte_gegen_schiffsparameter,  # Wertevalidierung gegen Schiffsdaten
    setze_schiff_manuell_wenn_notwendig,  # Schiff manuell auswÃ¤hlen
    split_by_gap,                     # Datengaps erkennen und segmentieren
    to_dezimalstunden, to_dezimalminuten, to_hhmmss,  # Zeitformat-Konvertierung
    initialisiere_polygon_werte,      # Einmalige Anreicherung mit Polygonattributen
    make_polygon_cache_key            # Erzeugung eindeutiger SchlÃ¼ssel fÃ¼r Caching
)

# === ðŸªŸ UI-Komponenten fÃ¼r Panels (Kennzahlen, Strecken etc.) ===
from modul_ui_panels import (
    feld_panel_template,
    panel_template,
    status_panel_template_mit_strecke,
    strecken_panel_template,
    dichte_panel_template,
    panel_template_dauer,
    zeige_bagger_und_verbringfelder,
    zeige_baggerwerte_panels,
    zeige_statuszeiten_panels,
    zeige_statuszeiten_panels_mit_strecke,
    zeige_strecken_panels,
    zeige_bonus_abrechnung_panels,
    zeige_aufsummierte_dauer_panels
)

# === ðŸ“ˆ Zeitreihengrafiken: Tiefe & Prozessdaten
from modul_prozessgrafik import zeige_baggerkopftiefe_grafik, zeige_prozessgrafik_tab

# ðŸ”„ Polygon-Auswertung: Aufenthaltsdauer je Status
from modul_polygon_auswertung import berechne_punkte_und_zeit
@st.cache_data
def berechne_punkte_und_zeit_cached(df, statuswert):
    return berechne_punkte_und_zeit(df, statuswert)

# ðŸ§® Zentrale Auswertung eines Umlaufs
from modul_berechnungen import berechne_umlauf_auswertung

# ðŸ—‚ï¸ Tabellen mit Umlaufzeiten, TDS, Verbringung
from modul_umlauftabelle import (
    berechne_gesamtzeiten,
    erzeuge_tds_tabelle,
    erzeuge_verbring_tabelle,
    erstelle_umlauftabelle,
    show_gesamtzeiten_dynamisch
)
@st.cache_data
def erzeuge_umlauftabelle_cached(umlauf_info_df, zeitzone, zeitformat):
    return erstelle_umlauftabelle(umlauf_info_df, zeitzone, zeitformat)

# ðŸ—ºï¸ Kartenansichten und Zentrum/Zoom berechnen
from modul_karten import plot_karte, zeige_umlauf_info_karte, berechne_map_center_zoom

# ðŸ“¥ Excel-Import fÃ¼r manuelle Feststoffdaten
from modul_daten_import import lade_excel_feststoffdaten
@st.cache_data
def lade_excel_feststoffdaten_cached(file):
    from modul_daten_import import lade_excel_feststoffdaten
    return lade_excel_feststoffdaten(file)

# ðŸ“Œ Dichtepolygone zuweisen (SchnittpunktprÃ¼fung)
from modul_dichtepolygon import weise_dichtepolygonwerte_zu

# ðŸ“ ASCII-Import von Dichtepolygon-Definitionen
@st.cache_data
def parse_dichte_polygone_cached(file_text, referenz_data, epsg_code):
    from modul_dichte_polygon_ascii import parse_dichte_polygone
    file_obj = io.StringIO(file_text)
    return parse_dichte_polygone(file_obj, referenz_data, epsg_code)

# ðŸ—ºï¸ Steuerung der Kartenelemente (Layer)
from modul_layersteuerung import zeige_layer_steuerung

from modul_tds_manager import initialisiere_manuell_df, merge_manuelle_daten


from streamlit_option_menu import option_menu
#============================================================================================
# ðŸ”µ Start der Streamlit App
#============================================================================================

# Streamlit Seiteneinstellungen (Titel und Layout)
st.set_page_config(page_title="TSHD Monitoring â€“ Baggerdatenanalyse", layout="wide")
st.title("ðŸš¢ TSHD Monitoring â€“ Baggerdatenanalyse")
st.sidebar.title("âš™ï¸ Datenimport | Einstellungen")


# ============================================================================================
# ðŸ”µ Datei-Upload mit automatischer Format-Erkennung
# ============================================================================================

with st.sidebar.expander("ðŸ“‚ Baggerdaten hochladen / auswÃ¤hlen", expanded=True):
    uploaded_files = st.file_uploader(
        "Datendateien (.txt) auswÃ¤hlen", 
        type=["txt"], 
        accept_multiple_files=True,
        key="daten_upload"
    )

    upload_status = st.empty()

    datenformat = None  # Initialisierung

    if uploaded_files:
        datenformat = erkenne_datenformat(uploaded_files)

        if datenformat in ["MoNa", "HPA"]:
            st.info(f"ðŸ“„ Erkanntes Datenformat: **{datenformat}**")
        else:
            st.warning("â“ Format konnte nicht eindeutig erkannt werden.")
            #datenformat = st.radio("ðŸ”„ Format manuell wÃ¤hlen:", ["MoNa", "HPA"], horizontal=True)


# ============================================================================================
# ðŸ”µ Datei-Upload fÃ¼r Bagger- und Verbringstellenpolygone
# ============================================================================================
with st.sidebar.expander("ðŸ—ºï¸ Polygone- und Solltiefen", expanded=False):

    uploaded_xml_files = st.file_uploader(
        "Baggerfeldgrenzen (XML)", 
        type=["xml"], 
        accept_multiple_files=True,
        key="xml_upload"
    )
    
    xml_status = st.empty()

# --- Solltiefen-Setup ---
    st.markdown("---")
    
    solltiefe_slider = st.number_input(
        "**Solltiefe (m)** \n_Nur falls keine XML mit gÃ¼ltiger Tiefe geladen wird_", 
        min_value=-30.0, max_value=0.0, 
        value=0.0, step=0.1, format="%.2f"
    )
    toleranz_oben = st.slider(
        "Obere Toleranz (m)", min_value=0.0, max_value=2.0, value=0.5, step=0.1
    )
    toleranz_unten = st.slider(
        "Untere Toleranz (m)", min_value=0.0, max_value=2.0, value=0.5, step=0.1
    )
# ============================================================================================
# ðŸ”µ Bonus-/Malussystem (Trennung von Berechnungsmethode und Importmethode)
# ============================================================================================

with st.sidebar.expander("ðŸ“ˆ Bonus-/Malussystem", expanded=False):

    # 1. Berechnungsmethode auswÃ¤hlen (wirkt sich auf spÃ¤tere TDS-Abrechnung aus)
    berechnungsmethode = st.radio("Berechnungsmethode wÃ¤hlen", ["HPA â€“ Dichtepolygone", "MoNa â€“ Lineare Interpolation"])
    methode_code = "hpa" if "HPA" in berechnungsmethode else "mona"
    st.session_state["bonus_methode"] = methode_code  # ðŸ”§ FÃ¼r spÃ¤tere Berechnungen merken



    # 2. UnabhÃ¤ngige Wahl der Importmethode fÃ¼r die Dichtewerte
    import_methode = st.radio("Importmethode der Dichtewerte", ["Dichtepolygone (CSV)", "Manuelle Eingabe"])
    st.session_state["bonus_importmethode"] = import_methode

    dichte_daten = []  # Wird mit Polygon- oder manuellen Daten gefÃ¼llt

    # ============================================================================================ 
    # --- Variante: Dichtepolygone aus CSV + optionaler JSON-Referenz importieren ---
    if import_methode == "Dichtepolygone (CSV)":
        uploaded_dichtefile = st.file_uploader("ðŸ“„ Dichtepolygone (CSV)", type=["csv", "txt", "tsv"])
        uploaded_json_file = st.file_uploader("ðŸ”§ Optional: Referenzwerte (JSON)", type=["json"])

        referenz_data = None
        if uploaded_json_file:
            try:
                referenz_data = json.load(uploaded_json_file)
                st.success("âœ… JSON geladen.")
            except Exception as e:
                st.warning(f"âš ï¸ Fehler beim JSON-Import: {e}")

        # Wenn Dichte-Datei vorhanden ist
        if uploaded_dichtefile:
            try:
                epsg_code = st.session_state.get("epsg_code", None)
                file_text = uploaded_dichtefile.getvalue().decode("utf-8")

                # Parsen der Polygoninformationen
                dichte_polygone = parse_dichte_polygone_cached(file_text, referenz_data, epsg_code)
                st.success(f"âœ… {len(dichte_polygone)} Dichtepolygone geladen.")

                # In DataFrame fÃ¼r UI-Editor umwandeln
                df_editor = pd.DataFrame([{
                    "Bereich": p["name"],
                    "Ortsdichte": p["ortsdichte"],
                    "Ortsspezifisch": p.get("ortspezifisch", None),
                    "Min. Baggerdichte": p.get("mindichte", None),
                    "Max. Dichte": p.get("maxdichte", None)
                } for p in dichte_polygone])

                # âœï¸ Formular zur Bearbeitung der Dichtewerte
                with st.form("dichtepolygon_editor_form"):
                    st.markdown("âœï¸ Bearbeite die Dichteparameter pro Polygon")
                    df_edit = st.data_editor(
                        df_editor,
                        hide_index=True,
                        use_container_width=True,
                        column_config={
                            "Ortsdichte": st.column_config.NumberColumn(format="%.3f"),
                            "Ortsspezifisch": st.column_config.NumberColumn(format="%.3f"),
                            "Min. Baggerdichte": st.column_config.NumberColumn(format="%.3f"),
                            "Max. Dichte": st.column_config.NumberColumn(format="%.3f"),
                        }
                    )
                    speichern = st.form_submit_button("ðŸ’¾ Ã„nderungen Ã¼bernehmen & speichern")

                # ðŸ”„ Ãœbernahme der Ã„nderungen ins Polygonobjekt
                if speichern:
                    for i, row in df_edit.iterrows():
                        dichte_polygone[i].update({
                            "ortsdichte": row["Ortsdichte"],
                            "ortspezifisch": row["Ortsspezifisch"],
                            "mindichte": row["Min. Baggerdichte"],
                            "maxdichte": row["Max. Dichte"]
                        })
                    st.success("âœ… Ã„nderungen gespeichert.")

                # Speichern in Session-State fÃ¼r spÃ¤tere Berechnung
                dichte_daten = dichte_polygone
                st.session_state["dichte_polygone"] = dichte_polygone
                st.session_state["bonus_dichtewerte"] = dichte_polygone

                # âž• Export als TXT-Datei
                if dichte_polygone:
                    export_lines = []
                    for poly in dichte_polygone:
                        name = poly.get("name", "")
                        ortsdichte = poly.get("ortsdichte") or 0
                        ortsspezifisch = poly.get("ortspezifisch") or 0
                        mindichte = poly.get("mindichte") or 0
                        maxdichte = poly.get("maxdichte") or 0
                        coords = poly.get("punkte_original", [])
                        for x, y in coords:
                            line = f"{name}\t{float(x):.2f}\t{float(y):.2f}\t{float(ortsdichte):.2f}\t{float(ortsspezifisch):.2f}\t{float(mindichte):.2f}\t{float(maxdichte):.2f}"
                            export_lines.append(line)

                    export_text = "\n".join(export_lines)

                    st.download_button(
                        label="ðŸ“¥ GeÃ¤nderte Dichtepolygone als TXT exportieren",
                        data=export_text.encode("utf-8"),
                        file_name="dichtepolygone_export.txt",
                        mime="text/plain"
                    )

            except Exception as e:
                st.error(f"âŒ Fehler beim Verarbeiten: {e}")
                st.text(traceback.format_exc())   

    # ============================================================================================    
    # --- Variante: Manuelle Eingabe ---
    elif import_methode == "Manuelle Eingabe":
        st.markdown("### Manuelle Eingabe fÃ¼r Dichtewerte")
        ortsdichte = st.number_input("Ortsdichte (t/mÂ³)", min_value=1.0, max_value=1.5, value=1.23, step=0.01)
        mindichte = st.number_input("Minimale Beladedichte", min_value=1.0, max_value=1.5, value=1.15, step=0.001)
        maxdichte = st.number_input("Maximale Beladedichte", min_value=1.0, max_value=1.5, value=1.29, step=0.001)
        ortsspezifisch = st.number_input("Ortsspezifischer TDS-Wert", min_value=0.0, max_value=1.0, value=0.25, step=0.001)

        if st.button("ðŸ’¾ Manuelle Werte Ã¼bernehmen"):
            dichte_daten = [{
                "name": "manuell",
                "ortsdichte": ortsdichte,
                "mindichte": mindichte,
                "maxdichte": maxdichte,
                "ortspezifisch": ortsspezifisch
            }]
            st.success("âœ… Manuelle Werte gespeichert.")

    # ============================================================================================ 
    # ðŸ” Einheitliches Zwischenspeichern aller Dichtewerte
    if dichte_daten:
        st.session_state["bonus_dichtewerte"] = dichte_daten
        st.session_state["dichte_polygone"] = dichte_daten  # ðŸ”§ FÃ¼r Funktionen wie initialisiere_polygon_werte()

    # âœ… Validierung je nach Berechnungsmethode
    werte_ok = True
    for eintrag in st.session_state.get("bonus_dichtewerte", []):
        if methode_code == "hpa":
            werte_ok = all(eintrag.get(k) not in [None, 0] for k in ["ortsdichte", "mindichte", "ortspezifisch"])
        elif methode_code == "mona":
            werte_ok = all(eintrag.get(k) not in [None, 0] for k in ["ortsdichte", "mindichte", "maxdichte"])
        if not werte_ok:
            break

    if not werte_ok:
        st.warning("âš ï¸ FÃ¼r die gewÃ¤hlte Methode fehlen notwendige Werte. Die Bonusberechnung ist derzeit nicht mÃ¶glich.")


#============================================================================================
# ðŸ”µ Berechnungs-Parameter in der Sidebar
#============================================================================================

# --- Dichteparameter Setup ---
with st.sidebar.expander("âš™ï¸ Setup - Berechnungen"):
    pf = st.number_input(
        "Feststoffdichte pf [t/mÂ³]",
        min_value=2.0, max_value=3.0,
        value=2.45, step=0.001, format="%.3f"
    )
    pw = st.number_input(
        "Wasserdichte pw [t/mÂ³]",
        min_value=0.98, max_value=1.1,
        value=1.000, step=0.001, format="%.3f"
    )

    pb = st.number_input(
        "Angenommene Bodendichte pb [t/mÂ³]",
        min_value=1.0, max_value=2.5,
        value=1.98, step=0.01, format="%.2f"
    )
    
    st.markdown("---") 
    
    min_fahr_speed = st.number_input(
        "Mindestgeschwindigkeit fÃ¼r Leerfahrt (knt)",
        min_value=0.0, max_value=2.0,
        value=0.30, step=0.01, format="%.2f"
    )

    min_vollfahrt_dauer_min = st.number_input(
        "â± Minimale Dauer fÃ¼r gÃ¼ltige Vollfahrtphase nach Status 2â†’3 (Minuten)",
        min_value=0.1,
        max_value=15.0,
        value=11.0,
        step=0.1,
        format="%.1f"
    )
    st.markdown("---") 
    # âœ… Toggle fÃ¼r Nutzung der Gemischdichte
    nutze_gemischdichte = st.toggle(
        "Gemischdichte fÃ¼r Start- und Endzeitpunkt Baggern verwenden?",
        value=True,
        help="Wenn aktiviert, wird die Gemischdichte zur Bestimmung des Beginns und Endes des Baggerns herangezogen."
    )


    dichte_grenze = st.number_input(
        "ðŸ”Ž min. Grenzwert Gemischdichte [t/mÂ³]",
        min_value=1.0, max_value=1.2, step=0.01, value=1.10,
        format="%.2f"
    )
    
    rueckblick_minute = st.slider(
        "â±ï¸ RÃ¼ckblickzeit (min) fÃ¼r GemischdichteprÃ¼fung - Statuswechsel 2 > 3", 
        min_value=0.0, max_value=4.0, step=0.5, value=2.0
    )
    st.markdown("---") 
    # âœ… Toggle korrekt einer Variable zuweisen
    nutze_schiffstrategie = st.toggle(
        "Start-/Endstrategien aus Schiffsdaten verwenden?",
        value=True,
        help="Wenn aktiviert, werden gespeicherte Strategien aus der Schiffsparameterdatei Ã¼bernommen."
    )

# Platzhalter fÃ¼r Erkennungsinfo Koordinatensystem
koordsys_status = st.sidebar.empty()

#============================================================================================
# ðŸ”µ MoNa-Daten verarbeiten und vorbereiten
#============================================================================================
if uploaded_files and datenformat not in ["MoNa", "HPA"]:
    st.warning("âš ï¸ Fehlerhafte Datei â€“ bitte Ã¼berprÃ¼fe Format und Inhalt.")
    st.stop()  # sofortiger Abbruch bei falschem Format

# âœ… Nur wenn gÃ¼ltiges Format, wird dieser Teil erreicht:
if uploaded_files:
    try:
        if datenformat == "MoNa":
            df, rw_max, hw_max = parse_mona_cached(uploaded_files)

        elif datenformat == "HPA":
            hpa_files = konvertiere_hpa_ascii_cached(uploaded_files)
            df, rw_max, hw_max = parse_mona_cached(hpa_files)

    except Exception as e:
        st.error("Fehler beim Laden der Daten:")
        st.exception(e)

    else:
        # âœ… Dieser Block wird nur ausgefÃ¼hrt, wenn KEIN Fehler aufgetreten ist
        upload_status.success(f"{len(df)} Zeilen aus {len(uploaded_files)} Datei(en) geladen")


        # TDS-Parameter berechnen
        df = berechne_tds_parameter(df, pf, pw)

        # Versuche, Schiff automatisch aus Dateinamen zu erkennen
        erkannter_schiffname = erkenne_schiff_aus_dateiname(uploaded_files)
        if erkannter_schiffname:
            df["Schiffsname"] = erkannter_schiffname
            
        # Koordinatensystem erkennen
        if not df.empty:
            proj_system, epsg_code, auto_erkannt = erkenne_koordinatensystem(
                df, st=st, status_element=koordsys_status
            )




            
#============================================================================================
# ðŸ”µ # ðŸ“‹ Time-Slider
#============================================================================================        
# Zeitbereich ermitteln aus df
        zeit_min = df["timestamp"].min()
        zeit_max = df["timestamp"].max()
        
        # Konvertierung zu nativen datetime-Objekten (wichtig fÃ¼r st.slider!)
        zeit_min = zeit_min.to_pydatetime()
        zeit_max = zeit_max.to_pydatetime()
        
        # Sidebar-Slider fÃ¼r Zeitfilter
        with st.sidebar.expander("ðŸ•“ Beobachtungszeitraum", expanded=False):
            zeitbereich = st.slider(
                "Zeitraum auswÃ¤hlen",
                min_value=zeit_min,
                max_value=zeit_max,
                value=(zeit_min, zeit_max),
                format="YYYY-MM-DD HH:mm",
                step=timedelta(minutes=15)  # â† direkt timedelta, nicht datetime.timedelta
            )
       
        # DataFrame auf ausgewÃ¤hlten Zeitraum filtern
        df = df[(df["timestamp"] >= zeitbereich[0]) & (df["timestamp"] <= zeitbereich[1])]
        # Bereite den Text vor
        start, ende = zeitbereich
        # Falls du UTC-Label brauchst, kannst du das hier hartkodiert oder dynamisch anpassen
        zeitraum_text = (
            f"{start.strftime('%d.%m.%Y %H:%M:%S')} â€“ {ende.strftime('%d.%m.%Y %H:%M:%S')} UTC"
        )

#============================================================================================
# ðŸ”µ # ðŸ“‹ Schiff zuweisen
#============================================================================================

        df, schiffsnamen = setze_schiff_manuell_wenn_notwendig(df, st)

        # Basisinfos: Schiffe & Zeitraum
        schiffe = df["Schiffsname"].dropna().unique()
        if len(schiffe) == 1:
            schiffsname_text = f"**Schiff:** **{schiffe[0]}**"
        elif len(schiffe) > 1:
            schiffsname_text = f"**Schiffe im Datensatz:** {', '.join(schiffe)}"
        else:
            schiffsname_text = "Keine bekannten Schiffsnamen gefunden."

       
        st.markdown(f"{schiffsname_text}  \n**Beobachtungszeitraum:** {zeitraum_text}")

        # Schiffsparameter laden und prÃ¼fen
        schiffsparameter = lade_schiffsparameter()

        if schiffsparameter:
            if len(schiffsnamen) == 1:
                st.sidebar.success(f"Schiffsparameter geladen ({len(schiffsparameter)} Schiffe) â€“ {schiffsnamen[0]}")
            else:
                st.sidebar.success(f"Schiffsparameter geladen ({len(schiffsparameter)} Schiffe)")
        else:
            st.sidebar.info("â„¹ï¸ Keine Schiffsparameter-Datei gefunden oder leer.")

        # PlausibilitÃ¤tsprÃ¼fung, falls ein Schiff eindeutig erkannt wurde
        if len(schiffsnamen) == 1:
            schiff = schiffsnamen[0]
            df, fehlerhafte = pruefe_werte_gegen_schiffsparameter(df, schiff, schiffsparameter)
            if fehlerhafte:
                for spalte, anzahl in fehlerhafte:
                    st.warning(f"âš ï¸ {anzahl} Werte in **{spalte}** auÃŸerhalb gÃ¼ltiger Grenzen fÃ¼r **{schiff}** â€“ wurden entfernt.")

#============================================================================================
# ðŸ”µ # ðŸ“‹ Schiffsparameter bearbeiten und speichern
#============================================================================================

        with st.sidebar.expander("ðŸ”§ Schiffsparameter", expanded=False):
            if len(schiffe) == 1:
                schiff = schiffe[0]
                st.markdown(f"**Aktives Schiff:** {schiff}")
        
                aktuelle_param = schiffsparameter.get(schiff, {})
                gespeicherte_seite = aktuelle_param.get("Baggerseite", "BB")
                erkannte_seite = erkenne_baggerseite(df)
        
                with st.form("schiffsparam_form"):
                    # ðŸ§­ Baggerseite
                    seite_auswahl = st.selectbox(
                        "ðŸ§­ Baggerseite wÃ¤hlen",
                        options=["Auto", "BB", "SB", "BB+SB"],
                        index=["Auto", "BB", "SB", "BB+SB"].index(gespeicherte_seite)
                    )
                    seite = erkannte_seite if seite_auswahl == "Auto" else seite_auswahl
        
                    # ðŸ“‹ Min/Max-Werte
                    alle_spalten = [
                        'Tiefgang_vorne', 'Tiefgang_hinten', 'Verdraengung',
                        'Tiefe_Kopf_BB', 'Tiefe_Kopf_SB',
                        'Gemischdichte_BB', 'Gemischdichte_SB',
                        'Gemischgeschwindigkeit_BB', 'Gemischgeschwindigkeit_SB',
                        'Fuellstand_BB_vorne', 'Fuellstand_SB_vorne',
                        'Fuellstand_BB_mitte', 'Fuellstand_SB_mitte',
                        'Fuellstand_SB_hinten', 'Fuellstand_BB_hinten',
                        'Masse_leeres_Schiff',
                        'Ladungsvolumen',
                        'Druck_vor_Baggerpumpe_BB', 'Druck_vor_Baggerpumpe_SB',
                        'Druck_hinter_Baggerpumpe_BB', 'Druck_hinter_Baggerpumpe_SB',
                        'Druck_Druckwasserpumpe_BB', 'Druck_Druckwasserpumpe_SB',
                    ]
                    daten = [{"Spalte": s,
                              "min": aktuelle_param.get(s, {}).get("min", None),
                              "max": aktuelle_param.get(s, {}).get("max", None)} for s in alle_spalten]
                    df_edit = pd.DataFrame(daten)
        
                    edited_df = st.data_editor(
                        df_edit,
                        column_config={
                            "Spalte": st.column_config.Column(disabled=True),
                            "min": st.column_config.NumberColumn(format="%.3f"),
                            "max": st.column_config.NumberColumn(format="%.3f"),
                        },
                        use_container_width=True,
                        hide_index=True
                    )
        
                    # ðŸ§­ Strategien
                    from modul_startend_strategie import STRATEGIE_REGISTRY
                    st.markdown("#### âš™ï¸ Start-/Endwert-Strategien")
        
                    startend_parameter = ["Verdraengung", "Ladungsvolumen"]
                    neue_strategien = {}
        
                    for parameter in startend_parameter:
                        st.markdown(f"**{parameter}**")
                        alte_strategie = aktuelle_param.get("StartEndStrategie", {}).get(parameter, {})
                        start_dict = STRATEGIE_REGISTRY["Start"]
                        start_keys = list(start_dict.keys())
                        start_labels = list(start_dict.values())
        
                        start_default = alte_strategie.get("Start", "standard")
                        start_index = start_keys.index(start_default) if start_default in start_keys else 0
        
                        start_neu_label = st.selectbox(
                            f"Startwert fÃ¼r {parameter}",
                            options=start_labels,
                            index=start_index,
                            key=f"{parameter}_start"
                        )
                        start_neu = start_keys[start_labels.index(start_neu_label)]
        
                        ende_dict = STRATEGIE_REGISTRY["Ende"]
                        ende_keys = list(ende_dict.keys())
                        ende_labels = list(ende_dict.values())
        
                        ende_default = alte_strategie.get("Ende", "standard")
                        ende_index = ende_keys.index(ende_default) if ende_default in ende_keys else 0
        
                        ende_neu_label = st.selectbox(
                            f"Endwert fÃ¼r {parameter}",
                            options=ende_labels,
                            index=ende_index,
                            key=f"{parameter}_ende"
                        )
                        ende_neu = ende_keys[ende_labels.index(ende_neu_label)]
        
                        neue_strategien[parameter] = {"Start": start_neu, "Ende": ende_neu}
        
                    # ðŸ’¾ Speichern-Button
                    speichern = st.form_submit_button("ðŸ’¾ Speichern fÃ¼r dieses Schiff (2x bestÃ¤tigen)")
        
                    if speichern:
                        neue_param = {
                            row["Spalte"]: {
                                "min": row["min"] if pd.notnull(row["min"]) else None,
                                "max": row["max"] if pd.notnull(row["max"]) else None
                            }
                            for _, row in edited_df.iterrows()
                        }
        
                        schiffsparameter[schiff] = {
                            **neue_param,
                            "Baggerseite": seite_auswahl,
                            "StartEndStrategie": neue_strategien
                        }
        
                        with open("schiffsparameter.json", "w", encoding="utf-8") as f:
                            json.dump(schiffsparameter, f, indent=2, ensure_ascii=False)
        
                        # ðŸ” aktualisiere lokale Kopie fÃ¼r sofortige Anzeige (optional, aber nÃ¼tzlich)
                        aktuelle_param = schiffsparameter[schiff]
        
                        st.success("âœ… Parameter gespeichert.")
            else:
                st.info("Bitte lade MoNa-Daten mit eindeutigem Schiffsname.")
  
            strategie = schiffsparameter.get(schiff, {}).get("StartEndStrategie", {})


#============================================================================================
# ðŸ”µ Filterleiste und Grundeinstellungen
#============================================================================================
        
        
        # ------------------------------------------------------------------------------------------------
        # ðŸ”¢ 1. Vier Spalten nebeneinander: Startwert, Umlaufauswahl, Zeitformat, Zeitzone
        # ------------------------------------------------------------------------------------------------
        st.markdown("---")
        col_startwert, col_umlauf, col_zeitformat, col_zeitzone = st.columns([1, 1, 1, 1])
        
        # ðŸ‘ˆ Auswahl: Startwert der UmlaufzÃ¤hlung (z.â€¯B. ab 1 oder hÃ¶her beginnen)
        with col_startwert:
            startwert = st.number_input("ðŸ”¢ Startwert UmlaufzÃ¤hlung", min_value=1, step=1, value=1)
        
        
        # ------------------------------------------------------------------------------------------------
        # ðŸ”„ 2. Berechne die UmlÃ¤ufe aus dem Datensatz (Leerfahrt â†’ Baggern â†’ Verbringen ...)
        #     â†’ nutzt Statuswechsel, Geschwindigkeit, Gemischdichte etc.
        # ------------------------------------------------------------------------------------------------
        umlauf_info_df = extrahiere_umlauf_startzeiten_cached(
            df,
            startwert=startwert,
            min_fahr_speed=min_fahr_speed,
            nutze_gemischdichte=nutze_gemischdichte,
            seite=seite,
            dichte_grenze=dichte_grenze,
            rueckblick_minute=rueckblick_minute,
            min_vollfahrt_dauer_min=min_vollfahrt_dauer_min
        )
        
        # ðŸ§ª Kopie zur spÃ¤teren parallelen Verwendung
        umlauf_info_df_all = umlauf_info_df.copy()
        
        # ðŸ“Š ErgÃ¤nze df um Status_neu-Spalte: Kennzeichnet z.â€¯B. 'Leerfahrt', 'Baggern' ...
        df = berechne_status_neu_cached(df, umlauf_info_df)



        # ------------------------------------------------------------------------------------------------
        # ðŸ“… 3. ErgÃ¤nze Spalten fÃ¼r spÃ¤tere Visualisierungen (Start-/Endzeit als eigene Spalten)
        # ------------------------------------------------------------------------------------------------
        if not umlauf_info_df.empty:
            if "Start Leerfahrt" in umlauf_info_df.columns:
                umlauf_info_df["start"] = umlauf_info_df["Start Leerfahrt"]
            if "Ende" in umlauf_info_df.columns:
                umlauf_info_df["ende"] = umlauf_info_df["Ende"]
        
        
       
        # ------------------------------------------------------------------------------------------------
        # ðŸ” 4. Auswahlbox: Welcher einzelne Umlauf soll betrachtet werden?
        # ------------------------------------------------------------------------------------------------
        
        # ðŸ’¡ Session-Reset fÃ¼r Umlaufauswahl, wenn Tab "TDS-Tabellen" aktiv ist
        if (
            "tab_auswahl" in st.session_state and 
            st.session_state["tab_auswahl"] == "TDS-Tabellen" and 
            st.session_state.get("umlauf_auswahl") != "Alle"
        ):
            del st.session_state["umlauf_auswahl"]
        
        with col_umlauf:
            umlauf_options = ["Alle"]
            if not umlauf_info_df.empty and "Umlauf" in umlauf_info_df.columns:
                umlauf_options += [int(u) for u in umlauf_info_df["Umlauf"]]
        
            # âœ… Wenn Tab "Prozessdaten", "Tiefenprofil" oder "Debug" aktiv ist UND Auswahl auf "Alle" steht â†’ auf ersten Umlauf setzen
            if (
                st.session_state.get("tab_auswahl") in ["Prozessdaten", "Tiefenprofil", "Debug"] and
                st.session_state.get("umlauf_auswahl") == "Alle" and
                len(umlauf_options) > 1
            ):
                st.session_state["umlauf_auswahl"] = umlauf_options[1]  # Index 1 = erster echter Umlauf (nach "Alle")
        
            # ðŸ§  Wenn Session-Flag aktiv ist, setze Auswahl automatisch auf "Alle"
            if st.session_state.get("bereit_fuer_berechnung", False):
                selected_index = 0
            else:
                selected_index = umlauf_options.index(
                    st.session_state.get("umlauf_auswahl", "Alle")
                ) if st.session_state.get("umlauf_auswahl", "Alle") in umlauf_options else 0
        
            # ðŸ“Œ Auswahlfeld anzeigen
            umlauf_auswahl = st.selectbox(
                "ðŸ” Umlauf auswÃ¤hlen",
                options=umlauf_options,
                index=selected_index,
                key="umlauf_auswahl"
            )

        
        # ------------------------------------------------------------------------------------------------
        # â±ï¸ 5. Formatierung fÃ¼r Zeitwerte: klassisch oder dezimal
        # ------------------------------------------------------------------------------------------------
        with col_zeitformat:
            zeitformat = st.selectbox(
                "ðŸ•’ Zeitformat",
                options=["hh:mm:ss", "dezimalminuten", "dezimalstunden"],
                index=1,
                format_func=lambda x: {
                    "hh:mm:ss": "hh:mm:ss",
                    "dezimalminuten": "Dezimalminuten",
                    "dezimalstunden": "Dezimalstunden"
                }[x]
            )
        # ------------------------------------------------------------------------------------------------
        # ðŸŒ 6. Zeitzone fÃ¼r Anzeige wÃ¤hlen (UTC oder Lokalzeit)
        # ------------------------------------------------------------------------------------------------
        with col_zeitzone:
            zeitzone = st.selectbox(
                "ðŸŒ Zeitzone",
                ["UTC", "Lokal (Europe/Berlin)"],
                index=0
            )
        # ------------------------------------------------------------------------------------------------
        # ðŸ•“ 7. Zeitzonen prÃ¼fen und ggf. auf UTC setzen
        # ------------------------------------------------------------------------------------------------
        # Wenn die Zeitstempel noch keine Zeitzone haben (naiv), â†’ auf UTC setzen.
        if df["timestamp"].dt.tz is None:
            df["timestamp"] = df["timestamp"].dt.tz_localize("UTC")
        
        # ------------------------------------------------------------------------------------------------
        # ðŸ” 8. UmlÃ¤ufe im DataFrame nummerieren
        # ------------------------------------------------------------------------------------------------
        # â†’ wichtig, da danach die Zuordnung zu 'Umlauf' fÃ¼r Filterung & Anzeige erfolgt
        df = nummeriere_umlaeufe(df, startwert=startwert)
        

        # ------------------------------------------------------------------------------------------------
        # ðŸ§¾ 9. Liste der verfÃ¼gbaren UmlÃ¤ufe vorbereiten (z.â€¯B. fÃ¼r Dropdown-Auswahl)
        # ------------------------------------------------------------------------------------------------
        verfuegbare_umlaeufe = df["Umlauf"].dropna().unique()
        verfuegbare_umlaeufe.sort()
        
        # ------------------------------------------------------------------------------------------------
        # ðŸ” 10. Initialisierung fÃ¼r Einzelanzeige: gewÃ¤hlte Zeile + zugehÃ¶rige Kennzahlen
        # ------------------------------------------------------------------------------------------------
        kennzahlen = {}  # Leeres Dictionary â€“ wird nur bei Auswahl eines Umlaufs gefÃ¼llt
        row = None       # Platzhalter fÃ¼r gewÃ¤hlte Umlaufzeile (eine einzelne Zeile aus der Tabelle)
        
        if umlauf_auswahl != "Alle":
            # ðŸ‘‰ Hole die Zeile, die dem gewÃ¤hlten Umlauf entspricht
            zeile = umlauf_info_df[umlauf_info_df["Umlauf"] == umlauf_auswahl]
            if not zeile.empty:
                row = zeile.iloc[0]  # ðŸŽ¯ Erste und einzige Treffer-Zeile extrahieren
                # ðŸ“Š Kennzahlen aus dieser Zeile und dem gesamten df berechnen (Volumen, Masse etc.)
                kennzahlen = berechne_umlauf_kennzahlen(row, df)
        
        # ------------------------------------------------------------------------------------------------
        # ðŸ“Š 11 Zeitbereich fÃ¼r Detailgrafiken setzen (z.â€¯B. Prozessgrafik, Tiefe etc.)
        # ------------------------------------------------------------------------------------------------
        # Erweitere den Bereich groÃŸzÃ¼gig um +/- 15 Minuten fÃ¼r Kontextanzeige
        if row is not None:
            t_start = pd.to_datetime(row["Start Leerfahrt"], utc=True) - pd.Timedelta(minutes=15)
            t_ende = pd.to_datetime(row["Ende"], utc=True) + pd.Timedelta(minutes=15)
        
            # ðŸ‘‰ Filtere den DataFrame fÃ¼r genau diesen Zeitraum â†’ df_context = Fokusbereich
            df_context = df[(df["timestamp"] >= t_start) & (df["timestamp"] <= t_ende)].copy()
        else:
            # Fallback: kein Umlauf ausgewÃ¤hlt â†’ ganzen Datensatz verwenden
            df_context = df.copy()


#============================================================================================
# ðŸ”µ Globale Layersteuerung
#============================================================================================

        # Auswahl wurde zuvor gesetzt
        
        show_status1_b, show_status2_b, show_status3_b, show_status456_b, show_status1_v, show_status2_v, show_status3_v, show_status456_v, auto_modus_aktiv = zeige_layer_steuerung(umlauf_auswahl)
     
#============================================================================================
# ðŸ”µ Baggerseite erkennen und auswÃ¤hlen
#============================================================================================

        # Auswahl der Baggerseite (Auto / BB / SB / BB+SB)

        seite_auswahl = locals().get("seite_auswahl", "Auto")
        erkannte_seite = locals().get("erkannte_seite", "BB")
        seite = erkannte_seite if seite_auswahl == "Auto" else seite_auswahl

#============================================================================================
# ðŸ”µ Rechtswerte normalisieren (nur fÃ¼r UTM)
#============================================================================================

        def normalisiere_rechtswert(wert):
            if proj_system == "UTM" and auto_erkannt and wert > 30_000_000:
                return wert - int(epsg_code[-2:]) * 1_000_000
            return wert

        # Anwenden auf relevante Spalten
        for col in ["RW_Schiff", "RW_BB", "RW_SB"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
            df[col] = df[col].apply(normalisiere_rechtswert)

#============================================================================================
# ðŸ”µ XML-Dateien (Baggerfelder) einlesen
#============================================================================================

        baggerfelder = []
        if uploaded_xml_files:
            try:
                for uploaded_xml in uploaded_xml_files:
                    try:
                        felder = parse_baggerfelder_cached(uploaded_xml, epsg_code)
                        baggerfelder.extend(felder)
                    except Exception as e:
                        st.sidebar.warning(f"{uploaded_xml.name} konnte nicht geladen werden: {e}")
                if baggerfelder:
                    xml_status.success(f"{len(baggerfelder)} Baggerfelder geladen")
                else:
                    xml_status.info("Keine Baggerfelder erkannt.")
            except Exception as e:
                xml_status.error(f"Fehler beim Verarbeiten der XML-Dateien: {e}")

#============================================================================================
# ðŸ”µ Dichtepolygone â€“ Zuweisung von Dichteparametern je Position innerhalb eines Umlaufs
#============================================================================================
        
        # ðŸ’¾ EPSG-Code (Koordinatensystem) im Session-State speichern
        #     â†’ wird spÃ¤ter z.â€¯B. fÃ¼r Umrechnung der Koordinaten gebraucht
        st.session_state["epsg_code"] = epsg_code
        
        # âœ… PrÃ¼fen, ob Dichtepolygone bereits geladen wurden (aus ASCII-Datei o.â€¯Ã¤.)
        if "dichte_polygone" in st.session_state:
            dichte_polygone = st.session_state["dichte_polygone"]
        
        # ðŸ” PrÃ¼fen, ob df bereits mit Polygonwerten angereichert wurde
        #     â†’ verhindert doppelte Berechnung bei erneutem Umlaufwechsel o.â€¯Ã¤.
        aktueller_key = make_polygon_cache_key(
            df, baggerfelder, st.session_state.get("dichte_polygone"),
            epsg_code, seite, toleranz_oben, toleranz_unten, solltiefe_slider
        )
        
        if st.session_state.get("polygon_key") == aktueller_key and "df_mit_polygon" in st.session_state:
            df = st.session_state["df_mit_polygon"]
        else:
            # âž• Neue Anreicherung nur wenn sich Parameter geÃ¤ndert haben
            df = initialisiere_polygon_werte(
                df,
                baggerfelder=baggerfelder,
                dichte_polygone=st.session_state.get("dichte_polygone"),
                epsg_code=epsg_code,
                seite=seite,
                toleranz_oben=toleranz_oben,
                toleranz_unten=toleranz_unten,
                solltiefe_slider=solltiefe_slider
            )
            st.session_state["df_mit_polygon"] = df
            st.session_state["polygon_key"] = aktueller_key
        

#============================================================================================
# ðŸ”¢ Berechnung von Kennzahlen und Zeitpunkten je Umlauf
#============================================================================================
        
        # ðŸ“Š Kennzahlen berechnen fÃ¼r jeden erkannten Umlauf
        #     â†’ z.â€¯B. Volumen, Masse, Dichte, Strecke etc.
        auswertungen = [berechne_umlauf_kennzahlen(row, df) for _, row in umlauf_info_df.iterrows()]
        df_auswertung = pd.DataFrame(auswertungen)
        
        
        
        # ðŸ”— Umlaufnummern ergÃ¤nzen (fÃ¼r spÃ¤tere TabellenverknÃ¼pfung)
        if not umlauf_info_df.empty and "Umlauf" in umlauf_info_df.columns:
            df_auswertung["Umlauf"] = umlauf_info_df["Umlauf"].values
        else:
            df_auswertung["Umlauf"] = pd.Series(dtype=int)  # Leere Spalte mit Typ
        
        # ðŸ•“ Zeitstempel des ersten Baggerpunkts je Umlauf ermitteln
        if df_auswertung.empty:
            st.warning("âš ï¸ Datei enthÃ¤lt keine vollstÃ¤ndigen UmlÃ¤ufe  â€“ Visualisierung nicht mÃ¶glich.")
            df_auswertung["timestamp_beginn_baggern"] = pd.NaT
        else:
            beginn_baggern_liste = []
        
            for umlauf_nummer in df_auswertung["Umlauf"]:
                # ðŸ” Suche passende Zeile im Info-DataFrame
                zeile = umlauf_info_df[umlauf_info_df["Umlauf"] == umlauf_nummer]
        
                if not zeile.empty:
                    # â±ï¸ Zeitfenster fÃ¼r â€žBaggernâ€œ bestimmen
                    start = pd.to_datetime(zeile.iloc[0]["Start Baggern"])
                    ende = pd.to_datetime(zeile.iloc[0]["Start Vollfahrt"])
        
                    # ðŸŒ Zeitzonen korrekt setzen
                    if start.tzinfo is None:
                        start = start.tz_localize("UTC")
                    if ende.tzinfo is None:
                        ende = ende.tz_localize("UTC")
        
                    # ðŸ”Ž Filter auf Baggerpunkte innerhalb des Zeitfensters
                    df_baggern = df[
                        (df["timestamp"] >= start) &
                        (df["timestamp"] <= ende) &
                        (df["Status_neu"] == "Baggern")
                    ]
        
                    erster_timestamp = df_baggern["timestamp"].min() if not df_baggern.empty else pd.NaT
                else:
                    erster_timestamp = pd.NaT
        
                beginn_baggern_liste.append(erster_timestamp)
        
            # ðŸ§¾ Neue Spalte anhÃ¤ngen
            df_auswertung["timestamp_beginn_baggern"] = beginn_baggern_liste
              
#============================================================================================
# ðŸ”µ Solltiefe auf Basis der Baggerfelder berechnen
#============================================================================================

        # ðŸ“¦ Smarter Caching-Mechanismus fÃ¼r Polygonanreicherung
        #     â†’ spart Rechenzeit, wenn sich Parameter nicht geÃ¤ndert haben
        aktueller_key = make_polygon_cache_key(
            df, baggerfelder, st.session_state.get("dichte_polygone"),
            epsg_code, seite, toleranz_oben, toleranz_unten, solltiefe_slider
        )
        
        if st.session_state.get("polygon_key") == aktueller_key and "df_mit_polygon" in st.session_state:
            df = st.session_state["df_mit_polygon"]
        else:
            # âž• Neue Anreicherung, wenn sich Parameter geÃ¤ndert haben
            df = initialisiere_polygon_werte(
                df,
                baggerfelder=baggerfelder,
                dichte_polygone=st.session_state.get("dichte_polygone"),
                epsg_code=epsg_code,
                seite=seite,
                toleranz_oben=toleranz_oben,
                toleranz_unten=toleranz_unten,
                solltiefe_slider=solltiefe_slider
            )
            st.session_state["df_mit_polygon"] = df
            st.session_state["polygon_key"] = aktueller_key
        
        # ðŸ§¾ Namen der Bagger- und Verbringfelder extrahieren (nur wenn Spalten vorhanden)
        bagger_namen = []
        verbring_namen = []
        
        if "Polygon_Name" in df.columns and "Status_neu" in df.columns:
            df_bagger = df[df["Status_neu"] == "Baggern"]
            df_verbring = df[df["Status_neu"] == "Verbringen"]
        
            bagger_namen = sorted(df_bagger["Polygon_Name"].dropna().unique())
            verbring_namen = sorted(df_verbring["Polygon_Name"].dropna().unique())
        
        # ðŸ”Ž Aktuelle Solltiefe bestimmen und Herkunft analysieren
        if "Solltiefe_Aktuell" in df.columns and df["Solltiefe_Aktuell"].notnull().any():
            gueltige = df["Solltiefe_Aktuell"].dropna()
            if (gueltige == gueltige.iloc[0]).all():
                solltiefe_wert = gueltige.iloc[0]  # Einheitlicher Wert im gesamten df
            else:
                solltiefe_wert = "variabel"       # Unterschiedliche Werte â†’ variabel
        else:
            solltiefe_wert = None                 # Keine Werte vorhanden
        
        # ðŸ§  Herkunftslogik: Bestimme, wie Solltiefe zustande kam
        if solltiefe_wert is None:
            solltiefe_herkunft = "nicht definiert"
        elif solltiefe_wert == solltiefe_slider:
            solltiefe_herkunft = "manuelle Eingabe"
        elif solltiefe_wert == "variabel":
            solltiefe_herkunft = "aus XML - mehrere Werte"
        else:
            solltiefe_herkunft = "aus XML-Datei Ã¼bernommen"
        
        # ðŸ“¤ Ausgabeformatierung der Solltiefe
        if isinstance(solltiefe_wert, (int, float)):
            anzeige_solltiefe = f"{solltiefe_wert:.2f}"
            anzeige_m = " m"
        elif solltiefe_wert == "variabel":
            anzeige_solltiefe = "variabel"
            anzeige_m = ""
        else:
            anzeige_solltiefe = " "
            anzeige_m = ""
#============================================================================================

        df_ungefiltert = df.copy()


#============================================================================================
# ðŸ”µ FESTSTOFFDATEN â€“ Manuelle Eingaben (CSV/Excel), ZusammenfÃ¼hrung, Bearbeitung in Sidebar
#============================================================================================

        # âœ… Relevante Daten in Session speichern (fÃ¼r spÃ¤tere Schritte / Module)
        st.session_state["umlauf_info_df_all"] = umlauf_info_df_all
        st.session_state["df_auswertung"] = df_auswertung

        # ðŸ“¦ Sidebar: Datenimport und manuelle Bearbeitung
        with st.sidebar.expander("ðŸ“¥ Feststoffdaten laden und bearbeiten", expanded=False):
            st.markdown("Lade CSV oder Excel mit Feststoffdaten. Bearbeite sie anschlieÃŸend direkt.")

            # ðŸ”„ Eingabedaten vorbereiten
            df_import = None           # CSV-Import
            df_excel_import = None     # Excel-Import

            # 1ï¸âƒ£ CSV-Datei hochladen (manuell gespeicherte Feststoffdaten)
            uploaded_csv = st.file_uploader("ðŸ“„ CSV (frÃ¼here Eingaben)", type=["csv"], key="sidebar_csv")
            if uploaded_csv:
                try:
                    df_import = pd.read_csv(uploaded_csv)
                    df_import["timestamp_beginn_baggern"] = pd.to_datetime(df_import["timestamp_beginn_baggern"], utc=True)
                    st.success("âœ… CSV erfolgreich geladen.")
                except Exception as e:
                    st.error(f"âŒ Fehler beim Einlesen der CSV: {e}")

            # 2ï¸âƒ£ Excel-Datei hochladen (z.â€¯B. Wochenbericht vom Schiff)
            uploaded_excel = st.file_uploader("ðŸ“˜ Excel: Wochenbericht vom Schiff", type=["xlsx"], key="sidebar_excel")
            if uploaded_excel:
                try:
                    df_excel_import = lade_excel_feststoffdaten_cached(uploaded_excel)
                    st.success("âœ… Excel erfolgreich geladen.")
                except Exception as e:
                    st.error(f"âŒ Fehler beim Einlesen der Excel-Datei: {e}")

            # 3ï¸âƒ£ Weiter nur, wenn beide Basisdaten vorhanden sind
            umlauf_info_df_all = st.session_state.get("umlauf_info_df_all", pd.DataFrame())
            df_auswertung = st.session_state.get("df_auswertung", pd.DataFrame())

            if not umlauf_info_df_all.empty and not df_auswertung.empty:
                # ðŸ” Typanpassung: Umlauf-Nummern mÃ¼ssen ganzzahlig sein
                df_auswertung["Umlauf"] = df_auswertung["Umlauf"].astype(int)
                umlauf_info_df_all["Umlauf"] = umlauf_info_df_all["Umlauf"].astype(int)

                # âœ³ï¸ Manuelle Datentabelle initialisieren (Basis: alle UmlÃ¤ufe)
                df_manuell = initialisiere_manuell_df(umlauf_info_df_all, df_auswertung)

                # ðŸ”— Daten aus CSV und Excel (sofern vorhanden) in die Tabelle einfÃ¼gen
                df_manuell, fehlende_merge_zeilen = merge_manuelle_daten(
                    df_manuell, df_csv=df_import, df_excel=df_excel_import
                )

                # ðŸ§  Aktuelle Version in den Session State schreiben
                st.session_state["df_manuell"] = df_manuell
                st.session_state["fehlende_merge_zeilen"] = fehlende_merge_zeilen

                # âš ï¸ Info bei fehlender Zuordnung (z.â€¯B. Zeitstempel nicht gefunden)
                if not fehlende_merge_zeilen.empty:
                    st.warning(f"âš ï¸ {len(fehlende_merge_zeilen)} UmlÃ¤ufe ohne passende CSV-/Excel-Zuordnung.")

                # âœï¸ Eingabemaske: Manuelle Daten direkt editieren
                st.markdown("#### âœï¸ Editor Feststoffwerte")
                df_editor = df_manuell.copy()

                df_editor_display = st.data_editor(
                    df_editor.loc[:, ["Umlauf", "timestamp_beginn_baggern", "feststoff", "proz_wert"]],
                    num_rows="dynamic",
                    use_container_width=True,
                    column_config={
                        "Umlauf": st.column_config.NumberColumn("Umlauf", disabled=True),
                        "timestamp_beginn_baggern": st.column_config.DatetimeColumn("Start Baggern", disabled=True),
                        "feststoff": st.column_config.NumberColumn("Ladung - Feststoff (mÂ³)", format="%.0f"),
                        "proz_wert": st.column_config.NumberColumn("Zentrifuge (%)", format="%.1f")
                    },
                    hide_index=True
                )

                # ðŸ’¾ Ãœberarbeitete Werte wieder speichern
                st.session_state["df_manuell"] = df_editor_display.copy()

                # ðŸ“¤ Exportbutton zum Speichern der Ã¼berarbeiteten Tabelle
                now_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                csv_data = df_editor_display.to_csv(index=False).encode("utf-8")
                csv_filename = f"{now_str}_manuell_feststoff.csv"

                st.download_button(
                    label="ðŸ“¥ Manuelle Feststoffwerte als .csv speichern",
                    data=csv_data,
                    file_name=csv_filename,
                    mime="text/csv"
                )
            else:
                st.info("â„¹ï¸ Noch keine Umlaufdaten oder Auswertung geladen.")

        df = mappe_umlaufnummer(df, umlauf_info_df)

#============================================================================================
# ðŸ”µ # Zentralisierte Berechnung nur bei Auswahl eines einzelnen Umlauf
#============================================================================================
    
        # ðŸŽ¯ Filtere die Daten fÃ¼r den ausgewÃ¤hlten Umlauf (sofern nicht "Alle" gewÃ¤hlt wurde)
        # ðŸ‘‰ Auswahlzeile vorbereiten, falls ein einzelner Umlauf gewÃ¤hlt ist
        zeile = umlauf_info_df[umlauf_info_df["Umlauf"] == umlauf_auswahl] if umlauf_auswahl != "Alle" else pd.DataFrame()
    
        if not zeile.empty:
            # ðŸ§¾ Einzelne Zeile (Umlauf) extrahieren
            row = zeile.iloc[0]
        
            # ðŸ—ºï¸ Zeige Karte und erhalte gefilterten DataFrame fÃ¼r diesen Umlauf
            df, _ = zeige_umlauf_info_karte(umlauf_auswahl, zeile, zeitzone, epsg_code, df)
        
            # ðŸ§  Erstelle Start-/Endstrategien pro Parameter (z.â€¯B. VerdrÃ¤ngung, Ladungsvolumen)
            if nutze_schiffstrategie:
                strategie = schiffsparameter.get(schiff, {}).get("StartEndStrategie", {})
            else:
                strategie = {
                    "Verdraengung": {"Start": None, "Ende": None},
                    "Ladungsvolumen": {"Start": None, "Ende": None}
                }
        
            # ðŸ“Š FÃ¼hre zentrale Auswertung fÃ¼r den gewÃ¤hlten Umlauf durch
            berechnungen = berechne_umlauf_auswertung(
                df, row, schiffsparameter, strategie, pf, pw, pb, zeitformat, epsg_code,
                df_manuell=st.session_state.get("df_manuell"),
                nutze_schiffstrategie=nutze_schiffstrategie,
                nutze_gemischdichte=nutze_gemischdichte  # â¬…ï¸ das ist neu!
            )

        
            # ðŸ“¦ Ergebnisse der Auswertung entpacken
            (
                tds_werte, werte, kennzahlen, strecken, strecke_disp, dauer_disp,
                debug_info, bagger_namen, verbring_namen, amob_dauer, dichtewerte, abrechnung
            ) = berechnungen
        
        else:
            # âš ï¸ Kein einzelner Umlauf ausgewÃ¤hlt â€“ Leere Initialisierung
            row = None
            tds_werte = werte = kennzahlen = strecken = strecke_disp = dauer_disp = debug_info = []
            bagger_namen = verbring_namen = []
            amob_dauer = 0.0
            dichtewerte = abrechnung = {}


# ============================================================================================
# ðŸŽ¨ HTML-Styling fÃ¼r KPI-Panel
#     âž¤ Definiert eigene CSS-Klassen zur optischen Gestaltung von Kennzahlen-Panels
#     âž¤ Wird spÃ¤ter z.â€¯B. fÃ¼r die Darstellung von Volumen, Masse etc. genutzt
# ============================================================================================
        
        st.markdown("""
        <style>
            .big-num {
                font-size: 2.5rem;
                font-weight: bold;
            }
            .panel {
                background: #f4f8fc;
                border-radius: 16px;
                padding: 20px;
                margin-bottom: 1.5rem;
            }
            .caption {
                font-size: 1rem;
                color: #555;
            }
            .highlight {
                font-weight: bold;
                font-size: 1.2rem;
                color: #0353a4;
            }
        </style>
        """, unsafe_allow_html=True)
        
        
# ============================================================================================
# ðŸŒ Karten-Transformer vorbereiten (EPSG â†’ WGS84)
#     âž¤ Zur Umrechnung von UTM oder anderen lokalen Koordinaten in GPS-Formate
#     âž¤ Voraussetzung fÃ¼r Mapbox-Darstellungen mit LÃ¤ngen-/Breitengraden
# ============================================================================================
        
        from pyproj import Transformer
        if epsg_code:
            transformer = Transformer.from_crs(epsg_code, "EPSG:4326", always_xy=True)
        else:
            transformer = None  # Optional: hier kÃ¶nnte man auch einen Fehler erzwingen bei fehlendem EPSG
        
        
# ============================================================================================
# ðŸ§­ Tab-Auswahl per PILL-Navigation (option_menu)
#     âž¤ Darstellung oben in der App, ersetzt klassische Tabs
#     âž¤ Optisch moderne Navigation (runde "Pills" mit Icons)
# ============================================================================================
        
        # ðŸ·ï¸ Klartext-Beschriftungen fÃ¼r Tabs (ohne Emojis)
        tab_labels = [
            "Karte",             # Interaktive Karte mit Fahrtspuren
            "Prozessdaten",      # ZeitverlÃ¤ufe & Sensorwerte
            "Tiefenprofil",      # Baggerkopftiefe
            "Umlauftabelle",     # Zeitliche Ãœbersicht aller UmlÃ¤ufe
            "TDS-Tabellen",      # Abrechnungstabellen (Feststoffmengen etc.)
            "Debug",             # Entwicklermodus mit Detailinfos
            # "Export"           # Optionaler Tab, derzeit deaktiviert
        ]
        
        # ðŸ–¼ï¸ Bootstrap-kompatible Icons fÃ¼r jede Tab-Kategorie
        tab_icons = [
            "geo",               # Karte
            "graph-up",          # Prozessdaten
            "activity",          # Tiefenprofil
            "journal-text",      # Umlauftabelle
            "journal-text",      # TDS (nochmals gleiches Icon)
            "tools"              # Debug-Modus
        ]
        
        # ðŸ’¡ Session-Init: WÃ¤hle standardmÃ¤ÃŸig den ersten Tab aus, wenn kein Zustand gesetzt ist
        if "tab_auswahl" not in st.session_state:
            st.session_state["tab_auswahl"] = tab_labels[0]
        
        # ðŸ“Œ Darstellung des horizontalen PILL-MenÃ¼s Ã¼ber `streamlit-option-menu`
        selected_tab = option_menu(
            menu_title=None,                    # Kein Titel oberhalb der Navigation
            options=tab_labels,                 # Auswahloptionen
            icons=tab_icons,                    # ZugehÃ¶rige Icons
            orientation="horizontal",           # Horizontal angeordnet
            styles={                            # Anpassung des Designs
                "container": {
                    "padding": "0!important",
                    "background-color": "#FFFFFF"
                },
                "nav-link": {
                    "font-size": "14px",
                    "margin": "0 8px",
                    "border-radius": "999px",   # Runde "Pills"
                    "padding": "8px 18px",
                    "color": "#333"
                },
                "nav-link-selected": {
                    "background-color": "#EBF2FC",
                    "color": "#3C598C"
                }
            },
            default_index=tab_labels.index(st.session_state["tab_auswahl"]),
            key="tab_auswahl"                   # Streamlit-State-SchlÃ¼ssel
        )
        
        # ðŸ§  AusgewÃ¤hlten Tab fÃ¼r die nachfolgende Logik zugÃ¤nglich machen
        selected_tab = st.session_state["tab_auswahl"]
        
        





# ============================================================================================
# Tab 1 - Ãœbersichtskarten
# ============================================================================================
        
        if selected_tab == "Karte":
            
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸŒ Karten-Transformer vorbereiten (fÃ¼r Plotly/Mapbox)
            # --------------------------------------------------------------------------------------------------------------------------
            transformer = Transformer.from_crs(epsg_code, "EPSG:4326", always_xy=True)
            zeit_suffix = "UTC" if zeitzone == "UTC" else "Lokal"
        
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸ“Œ Anzeige bei Auswahl eines einzelnen Umlaufs
            # --------------------------------------------------------------------------------------------------------------------------
            if umlauf_auswahl != "Alle" and row is not None:
                # ðŸ” Karte vorbereiten mit Info
                df_karten, _ = zeige_umlauf_info_karte(umlauf_auswahl, zeile, zeitzone, epsg_code, df)
        
                # ðŸ•“ Zeitbasierte Polygon-Auswertung
                bagger_df = berechne_punkte_und_zeit_cached(df, statuswert=2)
                bagger_zeiten = bagger_df["Zeit_Minuten"].to_dict()
        
                verbring_df = berechne_punkte_und_zeit_cached(df, statuswert=4)
                verbring_zeiten = verbring_df["Zeit_Minuten"].to_dict()
        
                # ðŸ§© Bagger-/Verbring-Felder anzeigen
                zeige_bagger_und_verbringfelder(
                    bagger_namen=bagger_namen,
                    verbring_namen=verbring_namen,
                    df=df,
                    baggerfelder=baggerfelder
                )
      
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸ“Œ Anzeige bei "Alle" â€“ einfache Ãœbersicht ohne Detailauswertung
            # --------------------------------------------------------------------------------------------------------------------------
            else:
                bagger_namen = []
                verbring_namen = []
                if "Polygon_Name" in df.columns and "Status_neu" in df.columns:
                    bagger_namen = sorted(df.loc[df["Status_neu"] == "Baggern", "Polygon_Name"].dropna().unique())
                    verbring_namen = sorted(df.loc[df["Status_neu"] == "Verbringen", "Polygon_Name"].dropna().unique())

        
                zeige_bagger_und_verbringfelder(
                    bagger_namen=bagger_namen,
                    verbring_namen=verbring_namen,
                    df=df,
                    baggerfelder=baggerfelder
                )
        
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸ—ºï¸ Kartenansichten nebeneinander (links = Baggern, rechts = Verbringen)
            # --------------------------------------------------------------------------------------------------------------------------
            col1, col2 = st.columns(2)
        
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸŸ¦ Linke Karte: Status 2 â€“ Baggerstelle
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸ“Œ Sicherstellen, dass Umlaufnummern vorhanden und korrekt sind


            with col1:
                fig, df_status2, df_456 = plot_karte(
                    df=df,
                    transformer=transformer,
                    seite=seite,
                    status2_label="Status 2 (Baggern)",
                    tiefe_spalte="Abs_Tiefe_Kopf_BB" if seite in ["BB", "BB+SB"] else "Abs_Tiefe_Kopf_SB",
                    mapbox_center={"lat": 53.5, "lon": 8.2},
                    zeitzone=zeitzone,
                    zeit_suffix=zeit_suffix,
                    baggerfelder=baggerfelder,
                    dichte_polygone=st.session_state.get("dichte_polygone"),
                    show_status1=show_status1_b,
                    show_status2=show_status2_b,
                    show_status3=show_status3_b,
                    show_status456=show_status456_b
                )
        
                if show_status2_b and not df_status2.empty:
                    map_center, zoom = berechne_map_center_zoom(df_status2, transformer)
                    fig.update_layout(mapbox_center=map_center, mapbox_zoom=zoom)
                elif show_status2_b:
                    st.info("Keine Daten mit Status 2 verfÃ¼gbar.")
        
                st.plotly_chart(fig, use_container_width=True, config={"scrollZoom": True}, key="karte_baggerstelle")
        
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸŸ¥ Rechte Karte: Status 4/5/6 â€“ Verbringstelle
            # --------------------------------------------------------------------------------------------------------------------------
            with col2:
                fig, df_status2, df_456 = plot_karte(
                    df=df,
                    transformer=transformer,
                    seite=seite,
                    status2_label="Status 2 (Verbringen)",
                    tiefe_spalte="Abs_Tiefe_Kopf_BB" if seite in ["BB", "BB+SB"] else "Abs_Tiefe_Kopf_SB",
                    mapbox_center={"lat": 53.5, "lon": 8.2},
                    zeitzone=zeitzone,
                    zeit_suffix=zeit_suffix,
                    baggerfelder=baggerfelder,
                    show_status1=show_status1_v,
                    show_status2=show_status2_v,
                    show_status3=show_status3_v,
                    show_status456=show_status456_v
                )
        
                if show_status456_v and not df_456.empty:
                    map_center, zoom = berechne_map_center_zoom(df_456, transformer)
                    fig.update_layout(mapbox_center=map_center, mapbox_zoom=zoom)
                elif show_status456_v:
                    st.info("Keine Daten mit Status 4, 5 oder 6 verfÃ¼gbar.")
        
                st.plotly_chart(fig, use_container_width=True, config={"scrollZoom": True}, key="karte_verbringstelle")
        
            # --------------------------------------------------------------------------------------------------------------------------
            # ðŸ“ Streckenanzeige (sofern Kennzahlen vorhanden)
            # --------------------------------------------------------------------------------------------------------------------------
            if kennzahlen:
                st.markdown("#### Strecken im Umlauf")
                zeige_strecken_panels(
                    strecke_disp["leerfahrt"], strecke_disp["baggern"], strecke_disp["vollfahrt"],
                    strecke_disp["verbringen"], strecke_disp["gesamt"],
                    dauer_disp["leerfahrt"], dauer_disp["baggern"], dauer_disp["vollfahrt"],
                    dauer_disp["verbringen"], dauer_disp["umlauf"],
                    strecken_panel_template
                )

#============================================================================================
# Tab 2 - Diagramm Prozessdaten
#============================================================================================
        
        elif selected_tab == "Prozessdaten":
            st.markdown("#### Umlaufgrafik â€“ Prozessdaten")
        
            if umlauf_auswahl != "Alle" and row is not None and tds_werte is not None:

                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“¦ Baggerdaten anzeigen: Masse, Volumen, Feststoffe, Bodenvolumen, Dichten
                # ----------------------------------------------------------------------------------------------------------------------
                    zeige_baggerwerte_panels(kennzahlen, tds_werte, zeitzone, pw, pf, pb, panel_template, dichte_panel_template)
                    
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“¦ Baggerdaten als Diagramm
                # ----------------------------------------------------------------------------------------------------------------------                    
                    zeige_prozessgrafik_tab(df_context, zeitzone, row, schiffsparameter, schiff, werte, seite, plot_key="prozessgrafik_tab2")

                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“¦ Abrechnung pro Umlauf
                # ----------------------------------------------------------------------------------------------------------------------
                    zeige_bonus_abrechnung_panels(tds_werte, dichtewerte, abrechnung, pw, pf, panel_template)                
                
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“Š Zeitliche Phasen anzeigen (Leerfahrt, Baggern und Strecken)
                # ----------------------------------------------------------------------------------------------------------------------
                    zeige_statuszeiten_panels_mit_strecke(row, zeitzone, zeitformat, strecken=strecke_disp, panel_template=status_panel_template_mit_strecke)

            else:
                st.info("Bitte einen konkreten Umlauf auswÃ¤hlen.")

# ============================================================================================
# Tab 3 - Diagramm Tiefe Baggerkopf (Modularisiert)
# ============================================================================================
       
        elif selected_tab == "Tiefenprofil":
            st.markdown("#### Baggerkopftiefe")
            if umlauf_auswahl != "Alle":
                zeige_baggerkopftiefe_grafik(
                    df,
                    zeitzone,
                    seite,
                    solltiefe=solltiefe_slider if solltiefe_wert is None else None,
                    toleranz_oben=toleranz_oben,
                    toleranz_unten=toleranz_unten
                )
            else:
                st.info("Bitte einen konkreten Umlauf auswÃ¤hlen.")
                
#============================================================================================
# Tab 4 - Umlauftabelle - gesamt 
#============================================================================================

        elif selected_tab == "Umlauftabelle":
            st.markdown("#### Auflistung aller UmlÃ¤ufe")
        
            if not umlauf_info_df.empty:
                # âœ… Extrahiere ALLE Umlauf-Startzeiten (unabhÃ¤ngig von Filtersicht)
        
                # ðŸ“… Erzeuge Tabelle mit einzelnen UmlÃ¤ufen und ihren Zeitabschnitten
                df_umlaeufe, list_leer, list_bagg, list_voll, list_verk, list_umlauf = erzeuge_umlauftabelle_cached(
                    umlauf_info_df, zeitzone, zeitformat
                )
        
                # â±ï¸ Berechne aufaddierte Gesamtzeiten
                gesamtzeiten = berechne_gesamtzeiten(list_leer, list_bagg, list_voll, list_verk, list_umlauf)
        
                # ðŸ§¾ Zeige Tabellen fÃ¼r UmlÃ¤ufe und Gesamtzeiten
                df_gesamt = show_gesamtzeiten_dynamisch(
                    gesamtzeiten["leerfahrt"], gesamtzeiten["baggern"],
                    gesamtzeiten["vollfahrt"], gesamtzeiten["verklapp"],
                    gesamtzeiten["umlauf"], zeitformat=zeitformat
                )
                # ðŸ”¢ Tabelle der EinzelumlÃ¤ufe
                st.dataframe(df_umlaeufe, use_container_width=True, hide_index=True)

                # âž• Panels fÃ¼r Gesamtdauer statt langweilige Tabelle
                st.markdown("#### Aufsummierte Dauer")
                zeige_aufsummierte_dauer_panels(df_gesamt)
            else:
                st.info("âš ï¸ Es wurden keine vollstÃ¤ndigen UmlÃ¤ufe erkannt.")
          
# ======================================================================================================================
# # Tab 5 â€“ ðŸ’  UMLAUFTABELLE: TDS-Berechnung pro Umlauf
# ======================================================================================================================
        
        # Dieser Tab dient der Anzeige, manuellen ErgÃ¤nzung und Berechnung von TDS-Kennzahlen je Umlauf
        elif selected_tab == "TDS-Tabellen":

            st.markdown("#### TDS Berechnung pro Umlauf")
        
            # ðŸ›‘ SicherheitsprÃ¼fung: Sind manuelle Feststoffdaten vorhanden?
            if "df_manuell" not in st.session_state or st.session_state["df_manuell"].empty:
                st.warning("âš ï¸ Keine Feststoffdaten vorhanden. Bitte CSV oder Excel Ã¼ber die Sidebar laden.")
                st.stop()
        
            # ðŸ”€ PrÃ¼fung der Umlauf-Auswahl â€“ nur "Alle" erlaubt fÃ¼r TDS-Gesamttabelle
            selected_umlauf = st.session_state.get("umlauf_auswahl", "Alle")
            if selected_umlauf != "Alle":
                st.info("ðŸ” Bitte 'Alle' im Umlauf-AuswahlmenÃ¼ wÃ¤hlen, um TDS-Tabelle zu berechnen.")
            else:
                # ðŸ”˜ Button zur Berechnung aktivieren
                if st.button("ðŸ“Š TDS-Tabelle berechnen"):
                    # ðŸš€ Starte zentrale Strategie-Definition (falls schiffspezifisch gewÃ¼nscht)
                    strategie = (
                        schiffsparameter.get(schiffsnamen[0], {}).get("StartEndStrategie", {})
                        if nutze_schiffstrategie else
                        {"Verdraengung": {"Start": None, "Ende": None}, "Ladungsvolumen": {"Start": None, "Ende": None}}
                    )
        
                    # â³ Starte TDS-Berechnung fÃ¼r alle UmlÃ¤ufe
                    with st.spinner("ðŸ”„ Berechne TDS-Kennzahlen fÃ¼r alle UmlÃ¤ufe..."):
                        df_tabelle, df_tabelle_export = erzeuge_tds_tabelle(
                            df, umlauf_info_df_all, schiffsparameter, strategie, pf, pw, pb, zeitformat, epsg_code
                        )
        
                        # ðŸ“¦ Ergebnisse in Session speichern
                        st.session_state["tds_df"] = df_tabelle
                        st.session_state["tds_df_export"] = df_tabelle_export
        
                        # ðŸ’¾ Export als Excel vorbereiten (2 TabellenblÃ¤tter)
                        now_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                        excel_buffer = io.BytesIO()
                        df_export_flat = df_tabelle_export.copy()
                        df_export_flat.columns = [
                            " - ".join(col).strip() if isinstance(col, tuple) else col
                            for col in df_export_flat.columns
                        ]
        
                        with pd.ExcelWriter(excel_buffer, engine="xlsxwriter") as writer:
                            # ðŸ“„ Export-Tabelle (roh)
                            df_export_flat.to_excel(writer, sheet_name="TDS-Werte", startrow=2, index=False, header=False)
                            worksheet = writer.sheets["TDS-Werte"]
                            for col_num, header in enumerate(df_export_flat.columns):
                                worksheet.write(0, col_num, header)
        
                            # ðŸ“Š Anzeige-Tabelle (formatiert)
                            df_anzeige = df_tabelle.copy()
                            df_anzeige.columns = [
                                " - ".join(col).strip() if isinstance(col, tuple) else col
                                for col in df_anzeige.columns
                            ]
                            df_anzeige.to_excel(writer, sheet_name="TDS-Anzeige", index=False)
        
                        # Speichern im Session-State
                        st.session_state["export_excel"] = excel_buffer.getvalue()
                        st.session_state["export_excel_filename"] = f"{now_str}_TDS_Tabelle.xlsx"
        
            # ðŸ“‹ TDS-Tabelle anzeigen, wenn vorhanden
            if "tds_df" in st.session_state:
                st.dataframe(st.session_state["tds_df"], use_container_width=True, hide_index=True)
        
            # ðŸ“¥ Export-Button fÃ¼r XLSX
            if st.session_state.get("export_excel"):
                st.download_button(
                    label="ðŸ“¥ TDS-Tabelle als .xlsx speichern",
                    data=st.session_state["export_excel"],
                    file_name=st.session_state["export_excel_filename"],
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("ðŸ”¹ Noch keine TDS-Tabelle berechnet.")
        
            # ---------------------------------------------------------------------------------------------------------------------
            # ðŸ“ Verbringstellen-Tabelle (WSA-konform)
            # ---------------------------------------------------------------------------------------------------------------------
            st.markdown("---")   
            st.markdown("#### Verbringstellen-Tabelle")
        
            if not df.empty:
                # ðŸ§® Berechnung der Verbringstellen (Zeitpunkt & Polygon)
                df_verbring_tab = erzeuge_verbring_tabelle(
                    df_ungefiltert,
                    umlauf_info_df_all,
                    transformer,
                    zeitzone=zeitzone,
                    status_col="Status_neu"
                )
        
                if df_verbring_tab.empty:
                    st.warning("âš ï¸ Keine Verbringstellen erkannt. PrÃ¼fe Polygone und Statuswerte (4/5/6).")
                else:
                    # ðŸ–¥ï¸ Tabelle anzeigen
                    st.dataframe(df_verbring_tab, use_container_width=True, hide_index=True)
        
                    # ðŸ“ Excel-Export ermÃ¶glichen
                    df_verbring_export = df_verbring_tab.copy()
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    dateiname = f"Verbringstellen_WSA_{schiff}_{timestamp}.xlsx"
        
                    excel_buffer = io.BytesIO()
                    df_verbring_export.to_excel(excel_buffer, index=True)
                    excel_buffer.seek(0)
        
                    st.download_button(
                        label="ðŸ“¥ WSA Verbringtabelle als .xlsx speichern",
                        data=excel_buffer,
                        file_name=dateiname,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            else:
                st.info("Bitte zuerst Daten laden.")
# ======================================================================================================================
# TAB 6 â€“ Numerische Auswertung Umlaufdaten: Panel-Templates fÃ¼r visuelle Darstellung
# ======================================================================================================================

        elif selected_tab == "Debug":
            if umlauf_auswahl != "Alle" and row is not None:

                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“Œ Anzeige Bagger- und Verbringfelder in Panel-Stil
                # ----------------------------------------------------------------------------------------------------------------------

                #st.markdown("#### Bagger- und Verbringfelder", unsafe_allow_html=True)
                
                bagger_felder_text = "<br>".join(sorted(bagger_namen)) if len(bagger_namen) > 0 else "-"
                verbring_felder_text = "<br>".join(sorted(verbring_namen)) if len(verbring_namen) > 0 else "-"


                zeige_bagger_und_verbringfelder(
                    bagger_namen=bagger_namen,
                    verbring_namen=verbring_namen,
                    df=df,
                    baggerfelder=baggerfelder  # â—ï¸wichtig!
                )

                
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“Š Zeitliche Phasen anzeigen (Leerfahrt, Baggern etc.)
                # ----------------------------------------------------------------------------------------------------------------------
                st.markdown("---")
                st.markdown("#### Statuszeiten im Umlauf", unsafe_allow_html=True)
                if kennzahlen:
                    zeige_statuszeiten_panels(row, zeitzone, zeitformat, panel_template)
                

                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“¦ Baggerdaten anzeigen: Masse, Volumen, Feststoffe, Bodenvolumen, Dichten
                # ----------------------------------------------------------------------------------------------------------------------
                    st.markdown("---")
                    st.markdown("#### Baggerwerte im Umlauf", unsafe_allow_html=True)
   
                    zeige_baggerwerte_panels(kennzahlen, tds_werte, zeitzone, pw, pf, pb, panel_template, dichte_panel_template)
                
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“¦ Abrechnung pro Umlauf
                # ----------------------------------------------------------------------------------------------------------------------
                    st.markdown("---")
                    st.markdown("#### Abrechnung pro Umlauf", unsafe_allow_html=True)
                    
                    zeige_bonus_abrechnung_panels(tds_werte, dichtewerte, abrechnung, pw, pf, panel_template)


               
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“ Streckenanzeige pro Umlauf
                # ----------------------------------------------------------------------------------------------------------------------
                    st.markdown("---")
                    st.markdown("#### Strecken im Umlauf")
              
                    zeige_strecken_panels(
                        strecke_disp["leerfahrt"], strecke_disp["baggern"], strecke_disp["vollfahrt"],
                        strecke_disp["verbringen"], strecke_disp["gesamt"],
                        dauer_disp["leerfahrt"], dauer_disp["baggern"], dauer_disp["vollfahrt"],
                        dauer_disp["verbringen"], dauer_disp["umlauf"],
                        strecken_panel_template
                    )
                # ----------------------------------------------------------------------------------------------------------------------
                # ðŸ“Š Zeitliche Phasen anzeigen (Leerfahrt, Baggern und Strecken)
                # ----------------------------------------------------------------------------------------------------------------------
                    st.markdown("---")  

                    st.markdown("#### Statuszeiten und Strecken im Umlauf", unsafe_allow_html=True)
                    zeige_statuszeiten_panels_mit_strecke(row, zeitzone, zeitformat, strecken=strecke_disp, panel_template=status_panel_template_mit_strecke)
           
                
                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ› ï¸ Debug-Infos (ausklappbar) â€“ Strategie-Auswertung und Werte anzeigen
                    # ----------------------------------------------------------------------------------------------------------------------
                    st.markdown("---")   
                    with st.expander("ðŸ› ï¸ Debug-Infos & Strategieergebnisse", expanded=False):
                        st.markdown(f"ðŸ” **Strategie Verdraengung**: `{strategie.get('Verdraengung', {})}`")
                        st.markdown(f"ðŸ” **Strategie Ladungsvolumen**: `{strategie.get('Ladungsvolumen', {})}`")
                    
                        for zeile in debug_info:
                            st.markdown(zeile)
                    
                        st.markdown("### ðŸ“‹ Ãœbersicht Start-/Endwerte laut Strategie")
                    
                        werte_tabelle = pd.DataFrame([
                            {
                                "Parameter": "Verdraengung Start",
                                "Wert": f"{werte['Verdraengung Start']:.2f}" if werte.get("Verdraengung Start") is not None else "-",
                                "Zeitstempel": sichere_zeit(werte.get("Verdraengung Start TS"), zeitzone)
                            },
                            {
                                "Parameter": "Verdraengung Ende",
                                "Wert": f"{werte['Verdraengung Ende']:.2f}" if werte.get("Verdraengung Ende") is not None else "-",
                                "Zeitstempel": sichere_zeit(werte.get("Verdraengung Ende TS"), zeitzone)
                            },
                            {
                                "Parameter": "Ladungsvolumen Start",
                                "Wert": f"{werte['Ladungsvolumen Start']:.2f}" if werte.get("Ladungsvolumen Start") is not None else "-",
                                "Zeitstempel": sichere_zeit(werte.get("Ladungsvolumen Start TS"), zeitzone)
                            },
                            {
                                "Parameter": "Ladungsvolumen Ende",
                                "Wert": f"{werte['Ladungsvolumen Ende']:.2f}" if werte.get("Ladungsvolumen Ende") is not None else "-",
                                "Zeitstempel": sichere_zeit(werte.get("Ladungsvolumen Ende TS"), zeitzone)
                            }
                        ])
                    
                        st.dataframe(werte_tabelle, use_container_width=True, hide_index=True)
                        st.dataframe(umlauf_info_df)
                     
                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Vorschau: Rohdaten
                    # ----------------------------------------------------------------------------------------------------------------------                        
                    with st.expander("ðŸ” Vorschau: Rohdaten (erste 20 Zeilen)", expanded=False):
                        if not df.empty:
                            st.caption(f"ðŸ“„ Zeige die ersten 20 von insgesamt {len(df)} Zeilen")
                            st.dataframe(df.head(20), use_container_width=True)
                        else:
                            st.info("â„¹ï¸ Noch keine Daten geladen.")
                     
                     
                        
                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Debug-Infos (ausklappbar) â€“ Verweilzeiten pro Polygon
                    # ----------------------------------------------------------------------------------------------------------------------
                                        
                    with st.expander("ðŸ“Š Verweilzeiten pro Polygon"):
                        df_bagger = berechne_punkte_und_zeit_cached(df, statuswert=2)
                        df_verbring = berechne_punkte_und_zeit_cached(df, statuswert=4)
            
                        st.write("**Baggerzeiten pro Feld (Status 2):**")
                        st.dataframe(df_bagger)
            
                        st.write("**Verbringzeiten pro Feld (Status 4):**")
                        st.dataframe(df_verbring) 
                        
                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Debug-Infos (ausklappbar) â€“ Verweilzeiten pro Dichte Polygon
                    # ----------------------------------------------------------------------------------------------------------------------                    
                    with st.expander("ðŸ“Œ HÃ¤ufigkeit Dichtepolygone"):
                        if "Dichte_Polygon_Name" in df.columns:
                            df_polygone = df["Dichte_Polygon_Name"].dropna()
                    
                            if not df_polygone.empty:
                                anzahl_gesamt = len(df_polygone)
                                haeufigkeit_df = (
                                    df_polygone.value_counts()
                                    .rename_axis("Polygon")
                                    .reset_index(name="Anzahl")
                                )
                                haeufigkeit_df["Anteil (%)"] = (haeufigkeit_df["Anzahl"] / anzahl_gesamt * 100).round(2)
                    
                                st.dataframe(haeufigkeit_df, use_container_width=True)
                            else:
                                st.info("Keine Polygon-Daten vorhanden in dieser Datei.")
                        else:
                            st.warning("Spalte 'Dichte_Polygon_Name' nicht gefunden.")                    
                    
                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Statuswerte im Umlauf
                    # ----------------------------------------------------------------------------------------------------------------------                     
                    with st.expander("ðŸ” Debug: Statusverlauf prÃ¼fen (nur gewÃ¤hlter Umlauf)", expanded=False):
                        if row is not None and not df.empty:
                            t_start = pd.to_datetime(row["Start Leerfahrt"], utc=True)
                            t_ende = pd.to_datetime(row["Ende"], utc=True)
                            df_debug = df[(df["timestamp"] >= t_start) & (df["timestamp"] <= t_ende)][["timestamp", "Status"]].copy()
                    
                            if "Status_neu" in df.columns:
                                df_debug["Status_neu"] = df["Status_neu"]
                            else:
                                df_debug["Status_neu"] = "nicht vorhanden"
                    
                            st.dataframe(df_debug, use_container_width=True, hide_index=True)
                    
                            # ðŸ”¢ Status_neu-Auswertung
                            if "Status_neu" in df_debug.columns:
                                status_counts = df_debug["Status_neu"].value_counts().reindex(
                                    ["Leerfahrt", "Baggern", "Vollfahrt", "Verbringen"], fill_value=0
                                )
                                unbekannt = df_debug["Status_neu"].isna().sum() + (df_debug["Status_neu"] == "nicht vorhanden").sum()
                    
                                st.markdown("**ðŸ§® Status-Phase-ZÃ¤hlung:**")
                                st.write(f"- ðŸš¢ Leerfahrt: **{status_counts['Leerfahrt']}**")
                                st.write(f"- âš’ï¸ Baggern: **{status_counts['Baggern']}**")
                                st.write(f"- ðŸ›³ï¸ Vollfahrt: **{status_counts['Vollfahrt']}**")
                                st.write(f"- ðŸŒŠ Verbringen: **{status_counts['Verbringen']}**")
                                st.write(f"- â“ Unbekannt / nicht vorhanden: **{unbekannt}**")
                    
                        else:
                            st.info("Kein Umlauf oder keine Daten geladen.")


                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š AMOB im Umlauf (erweiterter Debug)
                    # ----------------------------------------------------------------------------------------------------------------------
                    with st.expander("ðŸ§ª AMOB-Dauer (Debug-Ausgabe)", expanded=False):
                        st.write("ðŸ“¦ Umlauf-Info vorhanden:", not umlauf_info_df.empty)
                        st.write("ðŸ“¦ Zeitreihe vorhanden:", not df.empty)
                    
                        if amob_dauer is not None:
                            st.success(f"âœ… AMOB-Zeit fÃ¼r diesen Umlauf: **{amob_dauer:.1f} Sekunden**")
                    
                            # ðŸ” Typen checken
                            st.code(f"Typ von row['Umlauf']: {type(row['Umlauf'])}")
                            st.code(f"Typ von df['Umlauf']: {df['Umlauf'].dtype}")
                    
                            # ðŸ” Status-Werte prÃ¼fen
                            st.write("ðŸ§¾ Eindeutige Werte in Status_neu:")
                            st.dataframe(pd.DataFrame(df["Status_neu"].dropna().unique(), columns=["value"]))
                    
                            # ðŸ” VerfÃ¼gbare UmlÃ¤ufe
                            st.write("ðŸ” Vorhandene UmlÃ¤ufe im DF:")
                            st.dataframe(pd.DataFrame(df["Umlauf"].dropna().unique(), columns=["value"]))
                    
                            # ðŸ“Œ Aktueller Umlauf
                            st.write("ðŸ“Œ Aktuell untersuchter Umlauf:", row["Umlauf"])
                    
                            # ðŸ“ Anzahl Status=Baggern insgesamt
                            df_bagger_status = df[df["Status_neu"] == "Baggern"]
                            st.write(f"ðŸ” Anzahl Punkte mit Status_neu = 'Baggern' (gesamt): {len(df_bagger_status)}")
                    
                            # âœ… Typen angleichen
                            umlauf_id = str(row["Umlauf"])
                            df["Umlauf"] = df["Umlauf"].astype(str)
                    
                            df_bagg = df[(df["Umlauf"] == umlauf_id) & (df["Status_neu"] == "Baggern")].copy()
                            st.write(f"ðŸ” ...davon im aktuellen Umlauf: {len(df_bagg)}")
                    
                            if not df_bagg.empty:
                                df_bagg = df_bagg.sort_values("timestamp")
                                df_bagg["delta_t"] = df_bagg["timestamp"].diff().dt.total_seconds().fillna(0)
                                df_bagg["delta_t"] = df_bagg["delta_t"].apply(lambda x: x if x <= 30 else 0)  # Gaps >30â€¯s ignorieren
                                bagger_dauer_s = df_bagg["delta_t"].sum()
                    
                                anteil = (amob_dauer / bagger_dauer_s * 100) if bagger_dauer_s > 0 else 0
                                st.info(f"ðŸ” Baggerdauer: **{bagger_dauer_s:.1f} s**, AMOB-Anteil: **{anteil:.1f}â€¯%**")
                            else:
                                st.warning("âš ï¸ Keine Datenpunkte mit Status_neu = 'Baggern' im gewÃ¤hlten Umlauf gefunden.")
                    
                        else:
                            st.warning("âš ï¸ AMOB-Dauer wurde nicht berechnet oder ist `None`.")

                    # -----------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Dataframe
                    # -----------------------------------------------------------------------------------------------------------------            
                    with st.expander("ðŸ§ª Debug: Spalten im DataFrame"):
                        st.write("ðŸ§¾ Spalten im DataFrame:", df.columns.tolist())
                         # Debug-Tabelle: Ãœbersicht Dichtewerte je Umlauf

                    # ----------------------------------------------------------------------------------------------------------------------
                    # ðŸ“Š Abrechnungsfaktor
                    # ---------------------------------------------------------------------------------------------------------------------
                    with st.expander("ðŸ“Š Debug: Abrechnungsfaktor", expanded=False):
                        st.write("ðŸ”¢ Abrechnungsdaten:")
                        st.json(abrechnung)
        
  
            else:
                st.info("Bitte einen konkreten Umlauf auswÃ¤hlen.")
            

#=====================================================================================




elif not uploaded_files:
    st.info("Bitte lade mindestens eine Datei mit Baggerinformationen im Format MoNa- oder HPA hoch.")

